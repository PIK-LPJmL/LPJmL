#!/bin/bash 
###############################################################################
##                                                                           ##
##                 s  l  u  r  m  .  j  c  f                                 ##
##                                                                           ##
##  SLURM JCF file for running an Intel MPI job on the HLRS2015 cluster      ##
##  at PIK                                                                   ##
##                                                                           ##
###############################################################################
 
#SBATCH --ntasks=512
#SBATCH --qos=short
#SBATCH --tasks-per-node=128
##SBATCH --time=02:00:00
#SBATCH -J LPJmL60
#SBATCH --mail-user=bloh
#SBATCH --mail-type=end,fail

#SBATCH -o  lpjml.%j.out
#SBATCH -e  lpjml.%j.err

export LPJROOT=/p/projects/biodiversity/bloh/git/lpjml59_methane
version=$(cat $LPJROOT/VERSION)_noopt
export LPJRESTARTPATH=/p/projects/biodiversity/benchmark_run_outputs/${version}
export LPJOUTPATH=$LPJRESTARTPATH

mkdir -p $LPJRESTARTPATH/restart
mkdir -p $LPJOUTPATH/output
module list 2>&1
mpirun $LPJROOT/bin/lpjml --version
if mpirun $LPJROOT/bin/lpjml lpjml_config.cjson
then
  mpirun $LPJROOT/bin/lpjml -DFROM_RESTART lpjml_config.cjson
fi

rc=$?  # save return code of mpiexec

# copy log of LPJmL run to output directory
cp slurm.jcf $LPJOUTPATH
cp lpjml.$SLURM_JOB_ID.out $LPJOUTPATH
cp lpjml.$SLURM_JOB_ID.err $LPJOUTPATH

exit $rc
